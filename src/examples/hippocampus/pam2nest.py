# -*- coding: utf-8 -*-
"""
Created on Wed Apr  2 16:27:10 2014

This is a helper module with some functions to fastly use the data generated
by PAM in Nest

@author: martin
"""

import csv
import io
import logging
import os
import zipfile
import nest
import copy

logger = logging.getLogger(__package__)

def Connect(g1, g2, connections, delays, weights, delay_factor):
    """ Connects group g1 of neurons with group g2 of neurons using the
    connection- and delay-matrix generated by PAM
    
    g1,
    g2              : Groups of neurons
    
    connnections    : Connection matrix generated in PAM, which is a 
                      n * s matrix (n pre-synaptic neurons times s synapses)
    
    delays          : Delay matrix generated in PAM
    
    weights         : A standard weight for the connection
    
    delay_factor    : A factor for the delay
    
    
    Example:
        
        Connect(g1, g2, m['c'][0], m['d'][0], 2.0, DELAY_FACTOR)
    """
    for i in range(0, len(connections)):
        for j in range(0, len(connections[0])):
            # if a synapse has really been created
            if connections[i][j] > 0:
                nest.Connect([g1[i]], [g2[connections[i][j]]], 
                             params={'weight': weights, 
                                     'delay': delays[i][j] * delay_factor})


def CreateNetwork(data, neuron_type, weights, delay_factor):
    """ Creates the NEST-network for the dataset generated by PAM
    """
    
    if (len(weights) > 1) & (len(weights) < len(data['connections'][0])):
        print("hier")
        raise Exception("length of weight-vector does not match length of " +
            "connection list")
            
    neurongroups = []
    # first, create the neurongroups
    for ng in data['neurongroups'][0]:
        neurongroups.append(nest.Create(neuron_type, ng[-1]))
        
    # create connections between neuron groups
    for i, conn in enumerate(data['connections'][0]):
        if (len(weights) == 1):
            weight = weights[0];
        else:
            weight = weights[i]
            
        Connect(neurongroups[conn[1]], neurongroups[conn[2]], 
                data['c'][conn[0]], data['d'][conn[0]], 
                weight, delay_factor)
        
    return neurongroups        
        
#def convertToDict(data):
#    """ converts a given list of neuron groups to a dictionary """


def import_connections(filepath):
    matrices = copy.deepcopy(SUPPORTED_SUFFIXES)

    with zipfile.ZipFile(filepath, "r", zipfile.ZIP_DEFLATED) as file:
        for filename in file.namelist():
            filename_split = os.path.splitext(filename)
            filename_suffix = ''.join(filename_split[:-1]).rsplit("_", 1)[-1]
            filename_extension = filename_split[-1]

            print filename_suffix

            if filename_extension not in SUPPORTED_FILETYPES.keys():
                logger.error("filetype not supported")
                raise Exception("filetype not supported")

            if filename_suffix not in SUPPORTED_SUFFIXES.keys():
                logger.error("unknown suffix")
                raise Exception("unknown suffix")

            data = io.StringIO(unicode(file.read(filename)))
            func = SUPPORTED_FILETYPES[filename_extension]

            matrix = func(data)
            
            if filename_suffix in FULL_INTS.keys():
                matrix = convertToIntFull(matrix)
                
            if filename_suffix in PARTLY_INTS.keys():
                matrix = convertToIntPartly(matrix)                

            matrices[filename_suffix].append(matrix)

    return matrices


def import_UVfactors(filepath):
    result = []
    names = []
    with zipfile.ZipFile(filepath, "r", zipfile.ZIP_DEFLATED) as file:
        for filename in file.namelist():
            filename_split = os.path.splitext(filename)  
            filename_extension = filename_split[-1]
            
            data = io.StringIO(unicode(file.read(filename)))
            func = SUPPORTED_FILETYPES[filename_extension]
            matrix = func(data)
            result.append(matrix)
            names.append(filename_split[0])
    return result, names
            

def convertToIntFull(matrix):
    return [[int(i) for i in row] for row in matrix]
    
def convertToIntPartly(matrix):
    return [[row[0], row[1], int(row[2])] for row in matrix]    

def csv_read(data):
    reader = csv.reader(
        data,
        delimiter=";",
        quoting=csv.QUOTE_NONNUMERIC
    )
    return [row for row in reader]


SUPPORTED_FILETYPES = {
    ".csv": csv_read
}

FULL_INTS = {
    "c": [],
    "connections": []
}

PARTLY_INTS = {
    "neurongroups": []
}

SUPPORTED_SUFFIXES = {
    "d": [],
    "c": [],
    "connections": [],
    "neurongroups": []
}



if __name__ == "__main__":
    print import_zip("./test.zip")